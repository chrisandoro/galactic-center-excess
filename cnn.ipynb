{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1c2f29",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3923676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from functools import lru_cache\n",
    "from math import pi\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import trange\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "plt.rcParams[\"image.cmap\"] = \"inferno\"\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fafbc7",
   "metadata": {},
   "source": [
    "### Simulator Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547c247e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meshgrid(resolution, nx, ny, device=None):\n",
    "    \"\"\"\n",
    "    Constructs meshgrids.\n",
    "    \"\"\"\n",
    "    dx = resolution\n",
    "    dy = resolution\n",
    "\n",
    "    # Coordinates at pixel centers\n",
    "    x = torch.linspace(-1, 1, int(nx), device=device) * (nx - 1) * dx / 2\n",
    "    y = torch.linspace(-1, 1, int(ny), device=device) * (ny - 1) * dy / 2\n",
    "\n",
    "    # Note difference to numpy (!)\n",
    "    Y, X = torch.meshgrid((y, x), indexing='ij')\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Simulator:\n",
    "    extent: float = 15.0\n",
    "    \"\"\"Observation size [deg]\"\"\"\n",
    "\n",
    "    n_pix: int = 64\n",
    "    \"\"\"Number of pixels\"\"\"\n",
    "\n",
    "    d_gc: float = 8.3\n",
    "    \"\"\"Distance to galactic center [kpc]\"\"\"\n",
    "\n",
    "    sigma_pi0: float = 0.25\n",
    "    \"\"\"Length scale associated with spatial variations in pi0 emission [deg].\"\"\"\n",
    "\n",
    "    pi0_disk_height: float = 5.0\n",
    "    \"\"\"Disk height for pi0 emission\"\"\"\n",
    "\n",
    "    pi0_disk_radius: float = 20.0\n",
    "    \"\"\"Disk radius for pi0 emission\"\"\"\n",
    "\n",
    "    disk_height_ic: float = 5.0\n",
    "    \"\"\"Disk height for IC emission [deg].\"\"\"\n",
    "\n",
    "    bubble_smoothing_scale: float = 0.6\n",
    "    \"\"\"Smoothing scale for Fermi bubble template [deg].\"\"\"\n",
    "\n",
    "    ps_disk_height: float = 0.3\n",
    "    \"\"\"Disk scale height for disk-correlated point sources [kpc].\"\"\"\n",
    "\n",
    "    ps_disk_radius: float = 5.0\n",
    "    \"\"\"Disk scale radius for disk-correlated point sources [kpc].\"\"\"\n",
    "\n",
    "    dm_dist_concentration: float = 0.5\n",
    "    \"\"\"Steepness of DM emission.\"\"\"\n",
    "\n",
    "    dm_dist_scale: float = 5.0\n",
    "    \"\"\"Spatial scale of DM emission [deg].\"\"\"\n",
    "\n",
    "    containment_radius: float = 0.8 / 3\n",
    "    \"\"\"Very approximate 68% containment radius for PSF [deg].\"\"\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Image grid\n",
    "        self.resolution = 2 * self.extent / self.n_pix\n",
    "        self.X, self.Y = get_meshgrid(self.resolution, self.n_pix, self.n_pix)\n",
    "\n",
    "        # Gaussian kernel for point spread function used to blur the observation\n",
    "        X_k, Y_k = get_meshgrid(self.resolution, 5, 5)\n",
    "        self.psf_kernel = torch.exp(-(X_k**2 + Y_k**2) / (2 * self.containment_radius**2))\n",
    "\n",
    "        # Kernel for Gaussian process used to model pi0 emission\n",
    "        pts = torch.stack([self.X.flatten(), self.Y.flatten()])\n",
    "        d2s = ((pts[:, :, None] - pts[:, None, :]) ** 2).sum(0)\n",
    "        self.kernel_pi0 = (-d2s / (2 * self.sigma_pi0**2)).exp()\n",
    "\n",
    "    def sample_pi0_template(self):\n",
    "        \"\"\"\n",
    "        Samples pi0 emission\n",
    "        \"\"\"\n",
    "        # Manually rescale to make it look more realistic\n",
    "        emission = (self.kernel_pi0 @ torch.randn(self.n_pix**2)).reshape(\n",
    "            self.n_pix, self.n_pix\n",
    "        )\n",
    "        emission = 50 * torch.exp(emission / 8)\n",
    "        return (\n",
    "            emission\n",
    "            * torch.exp(-((self.X / self.pi0_disk_radius) ** 2))\n",
    "            * torch.exp(-((self.Y / self.pi0_disk_height) ** 2))\n",
    "        )\n",
    "\n",
    "    def template_ic(self):\n",
    "        \"\"\"\n",
    "        Gets IC emission, which is smooth and fixed\n",
    "        \"\"\"\n",
    "        return 25 * torch.exp(-self.Y.abs() / self.disk_height_ic)\n",
    "\n",
    "    def template_bubbles(self):\n",
    "        \"\"\"\n",
    "        Gets Fermi bubbles emission, which is smooth and fixed\n",
    "        \"\"\"\n",
    "        Y_norths = 10.5 * (torch.cosh((-self.X - 1) / 10.5) - 1) + 1\n",
    "        Y_souths = -8.7 * (torch.cosh((-self.X + 1.7) / 8.7) - 1) - 1\n",
    "        # Apply some hacky smoothing to the edges of the bubbles\n",
    "        emission = torch.zeros([self.n_pix, self.n_pix])\n",
    "        emission[self.Y > 0] = torch.sigmoid(\n",
    "            (self.Y[self.Y > 0] - Y_norths[self.Y > 0]) / self.bubble_smoothing_scale\n",
    "        )\n",
    "        emission[self.Y < 0] = torch.sigmoid(\n",
    "            (Y_souths[self.Y < 0] - self.Y[self.Y < 0]) / self.bubble_smoothing_scale\n",
    "        )\n",
    "        return 3 * emission\n",
    "\n",
    "    def template_dm(self):\n",
    "        \"\"\"\n",
    "        Computes smooth emission from DM annihilation\n",
    "        \"\"\"\n",
    "        dm_dist = dist.Gamma(self.dm_dist_concentration, 1 / self.dm_dist_scale)\n",
    "        # Distance to galactic center\n",
    "        rs = torch.sqrt(self.X**2 + self.Y**2)\n",
    "        return 100 * dm_dist.log_prob(rs).exp()\n",
    "\n",
    "    def _sample_ps_gc_xy(self, n: int):\n",
    "        # Use same distribution as for DM emission\n",
    "        ps_gc_dist = dist.Gamma(self.dm_dist_concentration + 1, 1 / self.dm_dist_scale)\n",
    "        rs = ps_gc_dist.sample((n,))\n",
    "        angles = torch.rand(n) * 2 * pi\n",
    "        xs = rs * torch.cos(angles)\n",
    "        ys = rs * torch.sin(angles)\n",
    "        return xs, ys\n",
    "\n",
    "    def _sample_ps_disk_xy(self, n: int):\n",
    "        # Convert to degrees\n",
    "        scale_radius = self.ps_disk_radius / self.d_gc * 180 / pi\n",
    "        scale_height = self.ps_disk_height / self.d_gc * 180 / pi\n",
    "\n",
    "        rs = dist.Exponential(1 / scale_radius).sample((n,))\n",
    "        ys = dist.Exponential(1 / scale_height).sample((n,))\n",
    "\n",
    "        # Randomly put pulsars above or below the galactic plane\n",
    "        ys *= 2 * ((torch.rand(n) > 0.5).float() - 0.5)\n",
    "\n",
    "        # Project radial coordinate\n",
    "        angles = 2 * pi * torch.rand(n)\n",
    "        xs = rs * torch.cos(angles)\n",
    "\n",
    "        return xs, ys\n",
    "\n",
    "    def _sample_pss_in_image(self, pos_sampler, n: int):\n",
    "        # Sample positions until n lie inside the image\n",
    "        xs, ys = pos_sampler(n)\n",
    "        while True:\n",
    "            idx_oob = (xs.abs() > self.extent) | (ys.abs() > self.extent)\n",
    "            n_oob = idx_oob.sum()\n",
    "            if n_oob == 0:\n",
    "                break\n",
    "            else:\n",
    "                xs[idx_oob], ys[idx_oob] = pos_sampler(n_oob)\n",
    "\n",
    "        return xs, ys\n",
    "\n",
    "    def _pixelate_pss(self, xs, ys, fluxes):\n",
    "        \"\"\"\n",
    "        Creates pixelated map by histogramming point source positions and fluxes.\n",
    "        \"\"\"\n",
    "        # Map onto pixel grid\n",
    "        bins = torch.linspace(-self.extent, self.extent, self.n_pix + 1)\n",
    "        return torch.histogramdd(\n",
    "            torch.stack([ys, xs], 1), bins=(bins, bins), weight=fluxes\n",
    "        ).hist\n",
    "\n",
    "    def sample(self) -> dict:\n",
    "        \"\"\"\n",
    "        Simulate all the emission components\n",
    "        \"\"\"\n",
    "        trace = {}\n",
    "\n",
    "        # Template normalizations\n",
    "        trace[\"A_ic\"] = torch.rand(1)\n",
    "        trace[\"A_pi0\"] = torch.rand(1)\n",
    "        trace[\"A_bubbles\"] = torch.rand(1)\n",
    "        trace[\"A_dm\"] = torch.rand(1)\n",
    "\n",
    "        # Sample pi0 template\n",
    "        trace[\"template_pi0\"] = self.sample_pi0_template()\n",
    "\n",
    "        # Number of point sources\n",
    "        n_ps_gc = trace[\"n_ps_gc\"] = torch.randint(low=200, high=800, size=(1,))\n",
    "        n_ps_disk = trace[\"n_ps_disk\"] = torch.randint(low=1000, high=4000, size=(1,))\n",
    "\n",
    "        # Sample fluxes\n",
    "        ps_log_flux_mean = 1.0\n",
    "        ps_log_flux_scale = 1.2\n",
    "        dist_ps_fluxes = dist.LogNormal(ps_log_flux_mean, ps_log_flux_scale)\n",
    "        ps_gc_fluxes = dist_ps_fluxes.sample((n_ps_gc,))\n",
    "        ps_disk_fluxes = dist_ps_fluxes.sample((n_ps_disk,))\n",
    "        # Sample positions\n",
    "        xs_ps_gc, ys_ps_gc = self._sample_pss_in_image(self._sample_ps_gc_xy, n_ps_gc)\n",
    "        xs_ps_disk, ys_ps_disk = self._sample_pss_in_image(self._sample_ps_disk_xy, n_ps_disk)\n",
    "        # Pixelate\n",
    "        trace[\"flux_ps_gc\"] = self._pixelate_pss(xs_ps_gc, ys_ps_gc, ps_gc_fluxes)\n",
    "        trace[\"flux_ps_disk\"] = self._pixelate_pss(xs_ps_disk, ys_ps_disk, ps_disk_fluxes)\n",
    "\n",
    "        trace[\"mu\"] = (\n",
    "            trace[\"A_ic\"] * self.template_ic()\n",
    "            + trace[\"A_pi0\"] * trace[\"template_pi0\"]\n",
    "            + trace[\"A_dm\"] * self.template_dm()\n",
    "            + trace[\"A_bubbles\"] * self.template_bubbles()\n",
    "            + trace[\"flux_ps_gc\"]\n",
    "            + trace[\"flux_ps_disk\"]\n",
    "        )\n",
    "\n",
    "        # Apply PSF and sample noise\n",
    "        mu_blurred = torch.nn.functional.conv2d(\n",
    "            trace[\"mu\"][None, None, :, :], self.psf_kernel[None, None, :, :], padding=2,\n",
    "        )[0, 0, :, :]\n",
    "\n",
    "        trace[\"img\"] = dist.Poisson(mu_blurred).sample()\n",
    "\n",
    "\n",
    "        return trace\n",
    "\n",
    "    def testsample(self, A_ic, A_pi0, A_bubbles, A_dm) -> dict:\n",
    "        \"\"\"\n",
    "        Simulate all the emission components\n",
    "        \"\"\"\n",
    "        trace = {}\n",
    "\n",
    "        # Template normalizations\n",
    "        trace[\"A_ic\"] = A_ic\n",
    "        trace[\"A_pi0\"] = A_pi0\n",
    "        trace[\"A_bubbles\"] = A_bubbles\n",
    "        trace[\"A_dm\"] = A_dm\n",
    "\n",
    "        # Sample pi0 template\n",
    "        trace[\"template_pi0\"] = self.sample_pi0_template()\n",
    "\n",
    "        # Number of point sources\n",
    "        n_ps_gc = trace[\"n_ps_gc\"] = torch.randint(low=200, high=800, size=(1,))\n",
    "        n_ps_disk = trace[\"n_ps_disk\"] = torch.randint(low=1000, high=4000, size=(1,))\n",
    "\n",
    "        # Sample fluxes\n",
    "        ps_log_flux_mean = 1.0\n",
    "        ps_log_flux_scale = 1.2\n",
    "        dist_ps_fluxes = dist.LogNormal(ps_log_flux_mean, ps_log_flux_scale)\n",
    "        ps_gc_fluxes = dist_ps_fluxes.sample((n_ps_gc,))\n",
    "        ps_disk_fluxes = dist_ps_fluxes.sample((n_ps_disk,))\n",
    "        # Sample positions\n",
    "        xs_ps_gc, ys_ps_gc = self._sample_pss_in_image(self._sample_ps_gc_xy, n_ps_gc)\n",
    "        xs_ps_disk, ys_ps_disk = self._sample_pss_in_image(self._sample_ps_disk_xy, n_ps_disk)\n",
    "        # Pixelate\n",
    "        trace[\"flux_ps_gc\"] = self._pixelate_pss(xs_ps_gc, ys_ps_gc, ps_gc_fluxes)\n",
    "        trace[\"flux_ps_disk\"] = self._pixelate_pss(xs_ps_disk, ys_ps_disk, ps_disk_fluxes)\n",
    "\n",
    "        trace[\"mu\"] = (\n",
    "            trace[\"A_ic\"] * self.template_ic()\n",
    "            + trace[\"A_pi0\"] * trace[\"template_pi0\"]\n",
    "            + trace[\"A_dm\"] * self.template_dm()\n",
    "            + trace[\"A_bubbles\"] * self.template_bubbles()\n",
    "            + trace[\"flux_ps_gc\"]\n",
    "            + trace[\"flux_ps_disk\"]\n",
    "        )\n",
    "\n",
    "        # Apply PSF and sample noise\n",
    "        mu_blurred = torch.nn.functional.conv2d(\n",
    "            trace[\"mu\"][None, None, :, :], self.psf_kernel[None, None, :, :], padding=2,\n",
    "        )[0, 0, :, :]\n",
    "\n",
    "        trace[\"img\"] = dist.Poisson(mu_blurred).sample()\n",
    "\n",
    "\n",
    "        return trace\n",
    "\n",
    "    def sample_batch(self, n) -> dict:\n",
    "        samples = [self.sample() for _ in range(n)]\n",
    "        return torch.utils.data.default_collate(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31186d54",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Example observation with each emission component plotted separately. The numbers in the subplots' titles show the mean flux in each pixel.\n",
    "\n",
    "(The color bars are all the same, which makes some components hard to see. You can change `vmax` to a lower value to make them more visible, or set `vmax=None` to set it automatically.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulator()\n",
    "sample = sim.sample()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, sample[\"flux_ps_gc\"], vmin=0, vmax=60)\n",
    "ax.set_title(f\"Galactic Center point sources: {sample['flux_ps_gc'].mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[0, 1]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, sample[\"flux_ps_disk\"], vmin=0, vmax=60)\n",
    "ax.set_title(f\"Disk point sources: {sample['flux_ps_gc'].mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[0, 2]\n",
    "flux_pi0 = sample[\"A_pi0\"] * sample[\"template_pi0\"]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, flux_pi0, vmin=0, vmax=60)\n",
    "ax.set_title(r\"$\\pi^0$/brem. diffuse: \" + f\"{flux_pi0.mean().item()}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[0, 3]\n",
    "flux_ic = sample[\"A_ic\"] * sim.template_ic()\n",
    "im = ax.pcolormesh(sim.X, sim.Y, flux_ic, vmin=0, vmax=60)\n",
    "ax.set_title(f\"Inverse Compton diffuse: {flux_ic.mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[1, 0]\n",
    "flux_bubbles = sample[\"A_bubbles\"] * sim.template_bubbles()\n",
    "im = ax.pcolormesh(sim.X, sim.Y, flux_bubbles, vmin=0, vmax=60)\n",
    "ax.set_title(f\"Fermi bubbles: {flux_bubbles.mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "flux_dm = sample[\"A_dm\"] * sim.template_dm()\n",
    "im = ax.pcolormesh(sim.X, sim.Y, flux_dm, vmin=0, vmax=60)\n",
    "ax.set_title(f\"Dark matter: {flux_dm.mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[1, 2]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, sample[\"mu\"], vmin=0, vmax=200)\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "ax.set_title(f\"Total: {sample['mu'].mean().item():.2f}\")\n",
    "\n",
    "ax = axes[1, 3]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, sample[\"img\"], vmin=0, vmax=200)\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "ax.set_title(f\"Observation: {sample['img'].mean().item():.2f}\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277f6db",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35565624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, simulator, size: int = 1000):\n",
    "        self.size = size  # number of simulations in an epoch\n",
    "        self.simulator = simulator\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.simulator.sample()  # generate a sample from the simulator\n",
    "        # sample[\"img\"] is generally what is observed by network\n",
    "        # sample[\"A_dm\"] is what we want to infer\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aae483a",
   "metadata": {},
   "source": [
    "### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63373bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ParamNet, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(64 * 16 * 16, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 4)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d9df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ParamNet().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "simulator = Simulator()\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "train_dataset = Dataset(simulator, size=10000)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        img_batch = batch[\"img\"].unsqueeze(1).float().to(device)\n",
    "        target_params = torch.stack([\n",
    "            batch[\"A_ic\"],\n",
    "            batch[\"A_pi0\"],\n",
    "            batch[\"A_bubbles\"],\n",
    "            batch[\"A_dm\"],\n",
    "        ], dim=1).float().to(device)\n",
    "\n",
    "        target_params = target_params.view(target_params.size(0), -1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img_batch)\n",
    "\n",
    "        loss = criterion(outputs, target_params)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbc153",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = Dataset(simulator, size=10000)  # create a validation dataset with 1000 samples\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# dictionary to store true and predicted values for each parameter\n",
    "param_true_values = {}\n",
    "param_predicted_values = {}\n",
    "\n",
    "# validation loop for each parameter\n",
    "for param_name, param_index in [(\"A_dm\", 0)]:\n",
    "    avg_val_loss = 0.0\n",
    "    true_values = []\n",
    "    predicted_values = []\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            img_batch = batch[\"img\"].unsqueeze(1).float().to(device)\n",
    "            target_params = torch.stack([\n",
    "                batch[\"A_ic\"],\n",
    "                batch[\"A_pi0\"],\n",
    "                batch[\"A_bubbles\"],\n",
    "                batch[\"A_dm\"],\n",
    "            ], dim=1).float().to(device)\n",
    "\n",
    "            outputs = model(img_batch)\n",
    "            loss = criterion(outputs[:, param_index].unsqueeze(1), target_params[:, param_index])\n",
    "            avg_val_loss += loss.item()\n",
    "\n",
    "            true_values.extend(target_params[:, param_index].cpu().numpy())\n",
    "            predicted_values.extend(outputs[:, param_index].cpu().numpy())\n",
    "\n",
    "        avg_val_loss /= len(val_loader)\n",
    "\n",
    "    print(f\"Validation Loss for {param_name}: {avg_val_loss:.4f}\")\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    for param_name, true_values in param_true_values.items():\n",
    "        predicted_values = param_predicted_values[param_name]\n",
    "\n",
    "        mae = mean_absolute_error(true_values, predicted_values)\n",
    "        print(f\"MAE for {param_name}: {mae:.4f}\")\n",
    "\n",
    "\n",
    "    # store the true and predicted values for each parameter\n",
    "    param_true_values[param_name] = true_values\n",
    "    param_predicted_values[param_name] = predicted_values\n",
    "\n",
    "    # plot the true vs predicted values\n",
    "    plt.scatter(true_values, predicted_values, label=param_name, color='purple')\n",
    "    plt.plot([0, 1], [0, 1], color='cyan', linestyle='--')\n",
    "    plt.xlabel(\"True Normalization Parameter\", fontsize = 15)\n",
    "    plt.ylabel(\"Predicted Normalization Parameter\", fontsize = 15)\n",
    "    plt.legend()\n",
    "    plt.ylim(0, 1.0)\n",
    "    plt.xlim(0, 1.0)\n",
    "    plt.title(f\"Truth vs Predicted Normalization Parameter for {param_name}\", fontsize = 15)\n",
    "    plt.show()\n",
    "\n",
    "print(\"Validation and plotting finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_true_values[\"A_dm\"] = true_values\n",
    "param_predicted_values[\"A_dm\"] = predicted_values\n",
    "\n",
    "num_bins = 20\n",
    "bin_edges = np.linspace(min(predicted_values), max(predicted_values), num_bins + 1)\n",
    "\n",
    "bin_indices = np.digitize(predicted_values, bin_edges)\n",
    "\n",
    "points_in_bins = {i: [] for i in range(1, num_bins + 1)}\n",
    "\n",
    "for bin_idx in range(1, num_bins + 1):\n",
    "    indices = np.where(bin_indices == bin_idx)[0]\n",
    "    for idx in indices:\n",
    "        points_in_bins[bin_idx].append((true_values[idx], predicted_values[idx]))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for bin_key, points in points_in_bins.items():\n",
    "    true_vals, pred_vals = zip(*points)\n",
    "    plt.scatter(true_vals, pred_vals, label=f'Bin {bin_key}',s=2)\n",
    "\n",
    "target_bin_index = 14\n",
    "\n",
    "bin_edge_low = bin_edges[target_bin_index]\n",
    "bin_edge_high = bin_edges[target_bin_index + 1]\n",
    "\n",
    "plt.axhline(y=bin_edge_low, color='red', linestyle='dashed', linewidth=1, label='Bin Border')\n",
    "plt.axhline(y=bin_edge_high, color='red', linestyle='dashed', linewidth=1, label='Bin Border')\n",
    "\n",
    "plt.axvline(x=0.7, color='red', linestyle='dashed', linewidth=2)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Points in Bins')\n",
    "plt.show()\n",
    "\n",
    "points_in_target_bin = np.count_nonzero(bin_indices == 11)\n",
    "print(points_in_target_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d46198",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 100\n",
    "bin_edges = np.linspace(min(predicted_values), max(predicted_values), num_bins + 1)\n",
    "\n",
    "target_predicted_value = 0.6  # replace with target predicted value\n",
    "\n",
    "bin_index = np.digitize(target_predicted_value, bin_edges)\n",
    "\n",
    "target_bin_count = np.sum(predicted_values == target_predicted_value)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(predicted_values, bins=bin_edges, color='blue', alpha=0.7, edgecolor='black')\n",
    "plt.axvline(x=target_predicted_value, color='red', linestyle='dashed', linewidth=2, label='Target Value, A_dm=0.7')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Posterior for A_dm=0.7')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Target Predicted Value: {target_predicted_value}\")\n",
    "print(f\"Bin Index: {bin_index}\")\n",
    "print(f\"Occurrences in Target Bin: {target_bin_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb4bc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlim(0,9)\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
