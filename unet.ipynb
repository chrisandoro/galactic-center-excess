{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from functools import lru_cache\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.distributions as dist\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm.auto import trange\n",
    "from tqdm import tqdm\n",
    "\n",
    "plt.rcParams[\"image.cmap\"] = \"inferno\"\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulator Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meshgrid(resolution, nx, ny, device=None):\n",
    "    \"\"\"\n",
    "    Constructs meshgrids.\n",
    "    \"\"\"\n",
    "    dx = resolution\n",
    "    dy = resolution\n",
    "\n",
    "    # Coordinates at pixel centers\n",
    "    x = torch.linspace(-1, 1, int(nx), device=device) * (nx - 1) * dx / 2\n",
    "    y = torch.linspace(-1, 1, int(ny), device=device) * (ny - 1) * dy / 2\n",
    "\n",
    "    # Note difference to numpy (!)\n",
    "    Y, X = torch.meshgrid((y, x), indexing='ij')\n",
    "\n",
    "    return X, Y\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Simulator:\n",
    "    extent: float = 15.0\n",
    "    \"\"\"Observation size [deg]\"\"\"\n",
    "\n",
    "    n_pix: int = 64\n",
    "    \"\"\"Number of pixels\"\"\"\n",
    "\n",
    "    d_gc: float = 8.3\n",
    "    \"\"\"Distance to galactic center [kpc]\"\"\"\n",
    "\n",
    "    sigma_pi0: float = 0.25\n",
    "    \"\"\"Length scale associated with spatial variations in pi0 emission [deg].\"\"\"\n",
    "\n",
    "    pi0_disk_height: float = 5.0\n",
    "    \"\"\"Disk height for pi0 emission\"\"\"\n",
    "\n",
    "    pi0_disk_radius: float = 20.0\n",
    "    \"\"\"Disk radius for pi0 emission\"\"\"\n",
    "\n",
    "    disk_height_ic: float = 5.0\n",
    "    \"\"\"Disk height for IC emission [deg].\"\"\"\n",
    "\n",
    "    bubble_smoothing_scale: float = 0.6\n",
    "    \"\"\"Smoothing scale for Fermi bubble template [deg].\"\"\"\n",
    "\n",
    "    ps_disk_height: float = 0.3\n",
    "    \"\"\"Disk scale height for disk-correlated point sources [kpc].\"\"\"\n",
    "\n",
    "    ps_disk_radius: float = 5.0\n",
    "    \"\"\"Disk scale radius for disk-correlated point sources [kpc].\"\"\"\n",
    "\n",
    "    dm_dist_concentration: float = 0.5\n",
    "    \"\"\"Steepness of DM emission.\"\"\"\n",
    "\n",
    "    dm_dist_scale: float = 5.0\n",
    "    \"\"\"Spatial scale of DM emission [deg].\"\"\"\n",
    "\n",
    "    containment_radius: float = 0.8 / 3\n",
    "    \"\"\"Very approximate 68% containment radius for PSF [deg].\"\"\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Image grid\n",
    "        self.resolution = 2 * self.extent / self.n_pix\n",
    "        self.X, self.Y = get_meshgrid(self.resolution, self.n_pix, self.n_pix)\n",
    "\n",
    "        # Gaussian kernel for point spread function used to blur the observation\n",
    "        X_k, Y_k = get_meshgrid(self.resolution, 5, 5)\n",
    "        self.psf_kernel = torch.exp(-(X_k**2 + Y_k**2) / (2 * self.containment_radius**2))\n",
    "\n",
    "        # Kernel for Gaussian process used to model pi0 emission\n",
    "        pts = torch.stack([self.X.flatten(), self.Y.flatten()])\n",
    "        d2s = ((pts[:, :, None] - pts[:, None, :]) ** 2).sum(0)\n",
    "        self.kernel_pi0 = (-d2s / (2 * self.sigma_pi0**2)).exp()\n",
    "\n",
    "    def sample_pi0_template(self):\n",
    "        \"\"\"\n",
    "        Samples pi0 emission\n",
    "        \"\"\"\n",
    "        # Manually rescale to make it look more realistic\n",
    "        emission = (self.kernel_pi0 @ torch.randn(self.n_pix**2)).reshape(\n",
    "            self.n_pix, self.n_pix\n",
    "        )\n",
    "        emission = 50 * torch.exp(emission / 8)\n",
    "        return (\n",
    "            emission\n",
    "            * torch.exp(-((self.X / self.pi0_disk_radius) ** 2))\n",
    "            * torch.exp(-((self.Y / self.pi0_disk_height) ** 2))\n",
    "        )\n",
    "\n",
    "    def template_ic(self):\n",
    "        \"\"\"\n",
    "        Gets IC emission, which is smooth and fixed\n",
    "        \"\"\"\n",
    "        return 25 * torch.exp(-self.Y.abs() / self.disk_height_ic)\n",
    "\n",
    "    def template_bubbles(self):\n",
    "        \"\"\"\n",
    "        Gets Fermi bubbles emission, which is smooth and fixed\n",
    "        \"\"\"\n",
    "        Y_norths = 10.5 * (torch.cosh((-self.X - 1) / 10.5) - 1) + 1\n",
    "        Y_souths = -8.7 * (torch.cosh((-self.X + 1.7) / 8.7) - 1) - 1\n",
    "        # Apply some hacky smoothing to the edges of the bubbles\n",
    "        emission = torch.zeros([self.n_pix, self.n_pix])\n",
    "        emission[self.Y > 0] = torch.sigmoid(\n",
    "            (self.Y[self.Y > 0] - Y_norths[self.Y > 0]) / self.bubble_smoothing_scale\n",
    "        )\n",
    "        emission[self.Y < 0] = torch.sigmoid(\n",
    "            (Y_souths[self.Y < 0] - self.Y[self.Y < 0]) / self.bubble_smoothing_scale\n",
    "        )\n",
    "        return 3 * emission\n",
    "\n",
    "    def template_dm(self):\n",
    "        \"\"\"\n",
    "        Computes smooth emission from DM annihilation\n",
    "        \"\"\"\n",
    "        dm_dist = dist.Gamma(self.dm_dist_concentration, 1 / self.dm_dist_scale)\n",
    "        # Distance to galactic center\n",
    "        rs = torch.sqrt(self.X**2 + self.Y**2)\n",
    "        return 100 * dm_dist.log_prob(rs).exp()\n",
    "\n",
    "    def _sample_ps_gc_xy(self, n: int):\n",
    "        # Use same distribution as for DM emission\n",
    "        ps_gc_dist = dist.Gamma(self.dm_dist_concentration + 1, 1 / self.dm_dist_scale)\n",
    "        rs = ps_gc_dist.sample((n,))\n",
    "        angles = torch.rand(n) * 2 * pi\n",
    "        xs = rs * torch.cos(angles)\n",
    "        ys = rs * torch.sin(angles)\n",
    "        return xs, ys\n",
    "\n",
    "    def _sample_ps_disk_xy(self, n: int):\n",
    "        # Convert to degrees\n",
    "        scale_radius = self.ps_disk_radius / self.d_gc * 180 / pi\n",
    "        scale_height = self.ps_disk_height / self.d_gc * 180 / pi\n",
    "\n",
    "        rs = dist.Exponential(1 / scale_radius).sample((n,))\n",
    "        ys = dist.Exponential(1 / scale_height).sample((n,))\n",
    "\n",
    "        # Randomly put pulsars above or below the galactic plane\n",
    "        ys *= 2 * ((torch.rand(n) > 0.5).float() - 0.5)\n",
    "\n",
    "        # Project radial coordinate\n",
    "        angles = 2 * pi * torch.rand(n)\n",
    "        xs = rs * torch.cos(angles)\n",
    "\n",
    "        return xs, ys\n",
    "\n",
    "    def _sample_pss_in_image(self, pos_sampler, n: int):\n",
    "        # Sample positions until n lie inside the image\n",
    "        xs, ys = pos_sampler(n)\n",
    "        while True:\n",
    "            idx_oob = (xs.abs() > self.extent) | (ys.abs() > self.extent)\n",
    "            n_oob = idx_oob.sum()\n",
    "            if n_oob == 0:\n",
    "                break\n",
    "            else:\n",
    "                xs[idx_oob], ys[idx_oob] = pos_sampler(n_oob)\n",
    "\n",
    "        return xs, ys\n",
    "\n",
    "    def _pixelate_pss(self, xs, ys, fluxes):\n",
    "        \"\"\"\n",
    "        Creates pixelated map by histogramming point source positions and fluxes.\n",
    "        \"\"\"\n",
    "        # Map onto pixel grid\n",
    "        bins = torch.linspace(-self.extent, self.extent, self.n_pix + 1)\n",
    "        return torch.histogramdd(\n",
    "            torch.stack([ys, xs], 1), bins=(bins, bins), weight=fluxes\n",
    "        ).hist\n",
    "\n",
    "    def sample(self) -> dict:\n",
    "        \"\"\"\n",
    "        Simulate all the emission components\n",
    "        \"\"\"\n",
    "        trace = {}\n",
    "\n",
    "        # Template normalizations\n",
    "        trace[\"A_ic\"] = torch.rand(1)\n",
    "        trace[\"A_pi0\"] = torch.rand(1)\n",
    "        trace[\"A_bubbles\"] = torch.rand(1)\n",
    "        trace[\"A_dm\"] = torch.rand(1)\n",
    "\n",
    "        # Sample pi0 template\n",
    "        trace[\"template_pi0\"] = self.sample_pi0_template()\n",
    "\n",
    "        # Number of point sources\n",
    "        n_ps_gc = trace[\"n_ps_gc\"] = torch.randint(low=200, high=800, size=(1,))\n",
    "        n_ps_disk = trace[\"n_ps_disk\"] = torch.randint(low=1000, high=4000, size=(1,))\n",
    "\n",
    "        # Sample fluxes\n",
    "        ps_log_flux_mean = 1.0\n",
    "        ps_log_flux_scale = 1.2\n",
    "        dist_ps_fluxes = dist.LogNormal(ps_log_flux_mean, ps_log_flux_scale)\n",
    "        ps_gc_fluxes = dist_ps_fluxes.sample((n_ps_gc,))\n",
    "        ps_disk_fluxes = dist_ps_fluxes.sample((n_ps_disk,))\n",
    "        # Sample positions\n",
    "        xs_ps_gc, ys_ps_gc = self._sample_pss_in_image(self._sample_ps_gc_xy, n_ps_gc)\n",
    "        xs_ps_disk, ys_ps_disk = self._sample_pss_in_image(self._sample_ps_disk_xy, n_ps_disk)\n",
    "        # Pixelate\n",
    "        trace[\"flux_ps_gc\"] = self._pixelate_pss(xs_ps_gc, ys_ps_gc, ps_gc_fluxes)\n",
    "        trace[\"flux_ps_disk\"] = self._pixelate_pss(xs_ps_disk, ys_ps_disk, ps_disk_fluxes)\n",
    "\n",
    "        trace[\"mu\"] = (\n",
    "            trace[\"A_ic\"] * self.template_ic()\n",
    "            + trace[\"A_pi0\"] * trace[\"template_pi0\"]\n",
    "            + trace[\"A_dm\"] * self.template_dm()\n",
    "            + trace[\"A_bubbles\"] * self.template_bubbles()\n",
    "            + trace[\"flux_ps_gc\"]\n",
    "            + trace[\"flux_ps_disk\"]\n",
    "        )\n",
    "\n",
    "        # Apply PSF and sample noise\n",
    "        mu_blurred = torch.nn.functional.conv2d(\n",
    "            trace[\"mu\"][None, None, :, :], self.psf_kernel[None, None, :, :], padding=2,\n",
    "        )[0, 0, :, :]\n",
    "\n",
    "        trace[\"img\"] = dist.Poisson(mu_blurred).sample()\n",
    "\n",
    "\n",
    "        return trace\n",
    "\n",
    "    def testsample(self, A_ic, A_pi0, A_bubbles, A_dm) -> dict:\n",
    "        \"\"\"\n",
    "        Simulate all the emission components\n",
    "        \"\"\"\n",
    "        trace = {}\n",
    "\n",
    "        # Template normalizations\n",
    "        trace[\"A_ic\"] = A_ic\n",
    "        trace[\"A_pi0\"] = A_pi0\n",
    "        trace[\"A_bubbles\"] = A_bubbles\n",
    "        trace[\"A_dm\"] = A_dm\n",
    "\n",
    "        # Sample pi0 template\n",
    "        trace[\"template_pi0\"] = self.sample_pi0_template()\n",
    "\n",
    "        # Number of point sources\n",
    "        n_ps_gc = trace[\"n_ps_gc\"] = torch.randint(low=200, high=800, size=(1,))\n",
    "        n_ps_disk = trace[\"n_ps_disk\"] = torch.randint(low=1000, high=4000, size=(1,))\n",
    "\n",
    "        # Sample fluxes\n",
    "        ps_log_flux_mean = 1.0\n",
    "        ps_log_flux_scale = 1.2\n",
    "        dist_ps_fluxes = dist.LogNormal(ps_log_flux_mean, ps_log_flux_scale)\n",
    "        ps_gc_fluxes = dist_ps_fluxes.sample((n_ps_gc,))\n",
    "        ps_disk_fluxes = dist_ps_fluxes.sample((n_ps_disk,))\n",
    "        # Sample positions\n",
    "        xs_ps_gc, ys_ps_gc = self._sample_pss_in_image(self._sample_ps_gc_xy, n_ps_gc)\n",
    "        xs_ps_disk, ys_ps_disk = self._sample_pss_in_image(self._sample_ps_disk_xy, n_ps_disk)\n",
    "        # Pixelate\n",
    "        trace[\"flux_ps_gc\"] = self._pixelate_pss(xs_ps_gc, ys_ps_gc, ps_gc_fluxes)\n",
    "        trace[\"flux_ps_disk\"] = self._pixelate_pss(xs_ps_disk, ys_ps_disk, ps_disk_fluxes)\n",
    "\n",
    "        trace[\"mu\"] = (\n",
    "            trace[\"A_ic\"] * self.template_ic()\n",
    "            + trace[\"A_pi0\"] * trace[\"template_pi0\"]\n",
    "            + trace[\"A_dm\"] * self.template_dm()\n",
    "            + trace[\"A_bubbles\"] * self.template_bubbles()\n",
    "            + trace[\"flux_ps_gc\"]\n",
    "            + trace[\"flux_ps_disk\"]\n",
    "        )\n",
    "\n",
    "        # Apply PSF and sample noise\n",
    "        mu_blurred = torch.nn.functional.conv2d(\n",
    "            trace[\"mu\"][None, None, :, :], self.psf_kernel[None, None, :, :], padding=2,\n",
    "        )[0, 0, :, :]\n",
    "\n",
    "        trace[\"img\"] = dist.Poisson(mu_blurred).sample()\n",
    "\n",
    "\n",
    "        return trace\n",
    "\n",
    "    def sample_batch(self, n) -> dict:\n",
    "        samples = [self.sample() for _ in range(n)]\n",
    "        return torch.utils.data.default_collate(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "Example observation with each emission component plotted separately. The numbers in the subplots' titles show the mean flux in each pixel.\n",
    "\n",
    "(The color bars are all the same, which makes some components hard to see. You can change `vmax` to a lower value to make them more visible, or set `vmax=None` to set it automatically.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = Simulator()\n",
    "sample = sim.sample()\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, sample[\"flux_ps_gc\"], vmin=0, vmax=60)\n",
    "ax.set_title(f\"Galactic Center point sources: {sample['flux_ps_gc'].mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[0, 1]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, sample[\"flux_ps_disk\"], vmin=0, vmax=60)\n",
    "ax.set_title(f\"Disk point sources: {sample['flux_ps_gc'].mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[0, 2]\n",
    "flux_pi0 = sample[\"A_pi0\"] * sample[\"template_pi0\"]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, flux_pi0, vmin=0, vmax=60)\n",
    "ax.set_title(r\"$\\pi^0$/brem. diffuse: \" + f\"{flux_pi0.mean().item()}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[0, 3]\n",
    "flux_ic = sample[\"A_ic\"] * sim.template_ic()\n",
    "im = ax.pcolormesh(sim.X, sim.Y, flux_ic, vmin=0, vmax=60)\n",
    "ax.set_title(f\"Inverse Compton diffuse: {flux_ic.mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[1, 0]\n",
    "flux_bubbles = sample[\"A_bubbles\"] * sim.template_bubbles()\n",
    "im = ax.pcolormesh(sim.X, sim.Y, flux_bubbles, vmin=0, vmax=60)\n",
    "ax.set_title(f\"Fermi bubbles: {flux_bubbles.mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[1, 1]\n",
    "flux_dm = sample[\"A_dm\"] * sim.template_dm()\n",
    "im = ax.pcolormesh(sim.X, sim.Y, flux_dm, vmin=0, vmax=60)\n",
    "ax.set_title(f\"Dark matter: {flux_dm.mean().item():.2f}\")\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "ax = axes[1, 2]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, sample[\"mu\"], vmin=0, vmax=200)\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "ax.set_title(f\"Total: {sample['mu'].mean().item():.2f}\")\n",
    "\n",
    "ax = axes[1, 3]\n",
    "im = ax.pcolormesh(sim.X, sim.Y, sample[\"img\"], vmin=0, vmax=200)\n",
    "plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "ax.set_title(f\"Observation: {sample['img'].mean().item():.2f}\")\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_aspect(\"equal\")\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, simulator, size: int = 1000):\n",
    "        self.size = size  # number of simulations in an epoch\n",
    "        self.simulator = simulator\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.simulator.sample()  # generate a sample from the simulator\n",
    "        # sample[\"img\"] is generally what is observed by network\n",
    "        # sample[\"A_dm\"] is what we want to infer\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        # encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 32)\n",
    "        self.enc2 = self.conv_block(32, 64)\n",
    "        self.enc3 = self.conv_block(64, 128)\n",
    "        self.enc4 = self.conv_block(128, 128)\n",
    "\n",
    "        # maxpooling\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "        # decoder\n",
    "        self.upconv3 = self.upconv_block(128, 128) # same as the bottleneck channels\n",
    "        self.dec3 = self.conv_block(256, 64) # concatenation of channels from encoder and upconv3\n",
    "        self.upconv2 = self.upconv_block(64, 32)\n",
    "        self.dec2 = self.conv_block(96, 32) # concatenation of channels from enc2 and upconv2\n",
    "        self.upconv1 = self.upconv_block(32, 16)\n",
    "        self.dec1 = self.conv_block(48, 16) # concatenation of channels from enc1 and upconv1\n",
    "        self.out = nn.Conv2d(16, out_channels, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # encoder\n",
    "        e1 = self.enc1(x)\n",
    "        p1 = self.pool(e1)\n",
    "\n",
    "        e2 = self.enc2(p1)\n",
    "        p2 = self.pool(e2)\n",
    "\n",
    "        e3 = self.enc3(p2)\n",
    "        p3 = self.pool(e3)\n",
    "\n",
    "        e4 = self.enc4(p3)\n",
    "\n",
    "        # decoder\n",
    "        up3 = self.upconv3(e4)\n",
    "        merge3 = torch.cat([e3, up3], dim=1)\n",
    "        d3 = self.dec3(merge3)\n",
    "\n",
    "        up2 = self.upconv2(d3)\n",
    "        merge2 = torch.cat([e2, up2], dim=1)\n",
    "        d2 = self.dec2(merge2)\n",
    "\n",
    "        up1 = self.upconv1(d2)\n",
    "        merge1 = torch.cat([e1, up1], dim=1)\n",
    "        d1 = self.dec1(merge1)\n",
    "\n",
    "        out = self.out(d1)\n",
    "        out=torch.sigmoid(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def upconv_block(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "# create instance of the UNet model\n",
    "model = UNet(1,2)\n",
    "\n",
    "# define optimizer (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# create dataset and dataloader\n",
    "train_dataset = Dataset(simulator, size=1000)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "loss_list = []\n",
    "# training loop\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch+1)\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, sample in enumerate(train_dataloader):\n",
    "        print(f\"Batch {batch_idx+1}/{len(train_dataloader)}\")\n",
    "        inputs = sample[\"img\"].unsqueeze(1)\n",
    "\n",
    "        targets_gc = torch.where(sample[\"flux_ps_gc\"] > 0.8, torch.tensor(1.0), torch.tensor(0.0)).float()\n",
    "        targets_disk = torch.where(sample[\"flux_ps_disk\"] > 0.8, torch.tensor(1.0), torch.tensor(0.0)).float()\n",
    "        targets = torch.stack([targets_gc, targets_disk], dim=1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # compute binary cross-entropy loss\n",
    "        criterion = nn.BCELoss()\n",
    "        loss = criterion(outputs, targets)\n",
    "        # backpropagation and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loss_list.append(running_loss)\n",
    "\n",
    "    # print average loss for the epoch\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss / len(train_dataloader)}\")\n",
    "\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sample = simulator.sample()\n",
    "\n",
    "validation_img = validation_sample[\"img\"][0]\n",
    "validation_img = validation_img.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "image = sample['img'][0].unsqueeze(0).unsqueeze(1)\n",
    "ground_truth_gc = sample['flux_ps_gc'][0]\n",
    "ground_truth_disk = sample['flux_ps_disk'][0]\n",
    "model_predictions = model(image).squeeze()\n",
    "\n",
    "threshold = 0.95\n",
    "binary_predictions = (model_predictions > threshold).float()\n",
    "\n",
    "pred = binary_predictions.unsqueeze(0).unsqueeze(1)[0]\n",
    "gt = (ground_truth_disk).unsqueeze(0).unsqueeze(1)\n",
    "\n",
    "observation = validation_img[0,0]\n",
    "prediction = pred[0,0].detach().cpu().numpy()\n",
    "ground_truth = gt[0,0]\n",
    "\n",
    "# create subplots\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "\n",
    "# observation\n",
    "axes[0].imshow(observation)\n",
    "axes[0].set_title('Observation')\n",
    "axes[0].axis('off')  # Hide axes for better visualization\n",
    "\n",
    "# prediction\n",
    "axes[1].imshow(prediction)\n",
    "axes[1].set_title('Prediction')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# ground truth\n",
    "axes[2].imshow(ground_truth)\n",
    "axes[2].set_title('Ground Truth')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
